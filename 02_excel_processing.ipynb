{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "import csv\n",
    "\n",
    "column_names = [\n",
    "    \"S. NO\", \"NAME OF RESERVOIR\", \"FRL (m)\", \"RESERVOIR LEVEL (m)\", \"LIVE CAPACITY AT FRL (BCM)\", \n",
    "    \"CURRENT LIVE STORAGE (BCM)\", \"DATE\", \"CURRENT YEAR\", \"LAST YEAR\", \"LAST 10 YEARS AVERAGE\", \n",
    "    \"IRR. (CCA) IN TH. HA\", \"HYDEL IN MW\"\n",
    "]\n",
    "\n",
    "txt_folder = \"./text\"\n",
    "excel_output = \"./excel-dir\"\n",
    "!rm -rf excel_output\n",
    "os.makedirs(excel_output, exist_ok=True)\n",
    "\n",
    "# pattern = re.compile(\n",
    "#     r'^\\*?(\\d+)\\s+([A-Z\\(\\)a-z\\s]+)\\s+([\\d.]+)\\s+([\\d.]+)\\s+([\\d.]+)\\s+([\\d.]+)\\s+(\\d{2}-\\d{2}-\\d{4})\\s+([\\d.]+)\\s+([\\d.]+)\\s+([\\d.]+)\\s+([\\d.-]+)\\s+([\\d.-]+)'\n",
    "# )\n",
    "\n",
    "# pattern = re.compile(\n",
    "#     r'(\\d+)\\s+(.+?)\\s+([\\d.]+)\\s+([\\d.]+)\\s+([\\d.]+)\\s+([\\d.]+)\\s+(\\d{2}-\\d{2}-\\d{4})\\s+([\\d.]+|\\s+)\\s+([\\d.]+|\\s+)\\s+([\\d.]+|\\s+)\\s+([\\d.-]+|\\s+)\\s+([\\d.-]+|\\s+)'\n",
    "# )\n",
    "pattern = re.compile(\n",
    "    r'^([*,&,#,@,!,$,%,^,(,),_,+]*\\d+)\\s+(.+?)\\s+([\\d.]+)\\s+([\\d.]+)\\s+([\\d.]+)\\s+([\\d.]+)\\s+(\\d{2}-\\d{2}-\\d{2,4})\\s+([\\d.]+|\\s+)\\s+([\\d.]+|\\s+)\\s+([\\d.]+|\\s+)\\s+([\\d.-]+|\\s+)\\s+([\\d.-]+|\\s+)'\n",
    ")\n",
    "\n",
    "for idx,filename in enumerate(os.listdir(txt_folder)):\n",
    "    # if(idx>0):\n",
    "    #     break\n",
    "    filepath = os.path.join(txt_folder, filename)\n",
    "    excelpath = os.path.join(excel_output, filename.replace(\".txt\",\".csv\"))\n",
    "    extracted_lines = []\n",
    "    with open(filepath, 'r') as file:\n",
    "            lines = file.readlines()\n",
    "            for line in lines:\n",
    "                match = pattern.match(line)\n",
    "                if match:\n",
    "                    extracted_lines.append(match.groups())\n",
    "    with open(excelpath, 'w', newline='') as csvfile:\n",
    "        csvwriter = csv.writer(csvfile)\n",
    "        csvwriter.writerow(column_names)\n",
    "        csvwriter.writerows(extracted_lines)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "\n",
    "csv_folder = \"./excel-dir\"\n",
    "unique_reservoirs = set()\n",
    "\n",
    "for filename in os.listdir(csv_folder):\n",
    "    if filename.endswith(\".csv\"):\n",
    "        filepath = os.path.join(csv_folder, filename)\n",
    "        df = pd.read_csv(filepath)\n",
    "        reservoir_names = df[\"NAME OF RESERVOIR\"].astype(str)  # Convert to string to handle mixed data types\n",
    "\n",
    "        for name in reservoir_names:\n",
    "            unique_reservoirs.add(name)\n",
    "\n",
    "print(\"Unique reservoir names found (excluding numbers):\")\n",
    "display(len(unique_reservoirs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ALIYAR',\n",
       " 'ALMATTI',\n",
       " 'ATAL SAGAR(MADIKHEDA)',\n",
       " 'BALIMELA',\n",
       " 'BANSAGAR',\n",
       " 'BARGI',\n",
       " 'BARNA DAM',\n",
       " 'BARVI DAM',\n",
       " 'BHADAR',\n",
       " 'BHADRA',\n",
       " 'BHAMA ASKHED',\n",
       " 'BHANDARDARA',\n",
       " 'BHATGHAR',\n",
       " 'BHATSA',\n",
       " 'BHIMA(UJJANI)',\n",
       " 'BISALPUR',\n",
       " 'BRAHMANI(GUJ)',\n",
       " 'CHANDAN DAM',\n",
       " 'CHASKAMAN',\n",
       " 'DAMANGANGA',\n",
       " 'DANTIWADA',\n",
       " 'DARNA DAM',\n",
       " 'DHOM',\n",
       " 'DIMBHE DAM',\n",
       " 'DONKARAYI',\n",
       " 'DOYANG HEP',\n",
       " 'DUDHAWA',\n",
       " 'DUDHGANGA',\n",
       " 'GANDHI SAGAR',\n",
       " 'GERUSOPPA',\n",
       " 'GETALSUD',\n",
       " 'GHATAPRABHA(HIDKAL)',\n",
       " 'GIRNA',\n",
       " 'GOBIND SAGAR(BHAKRA)',\n",
       " 'GUMTI',\n",
       " 'HARANGI',\n",
       " 'HARIHARJHOR',\n",
       " 'HATHMATI',\n",
       " 'HEMAVATHY',\n",
       " 'HIRAKUD',\n",
       " 'IDAMALAYAR',\n",
       " 'IDUKKI',\n",
       " 'INDIRA SAGAR',\n",
       " 'ISAPUR',\n",
       " 'JAISAMAND',\n",
       " 'JAWAI DAM',\n",
       " 'JAYAKWADI(PAITHAN)',\n",
       " 'JHAKAM',\n",
       " 'JIRGO',\n",
       " 'KABINI',\n",
       " 'KADANA',\n",
       " 'KADDAM (K.N.R.)',\n",
       " 'KAKKI',\n",
       " 'KALLADA(PARAPPAR)',\n",
       " 'KANDALERU',\n",
       " 'KANGSABATI',\n",
       " 'KANHER',\n",
       " 'KARJAN',\n",
       " 'KHADAKVASLA',\n",
       " 'KHANDONG',\n",
       " 'KOL DAM',\n",
       " 'KOLAR DAM',\n",
       " 'KONAR',\n",
       " 'KOYANA',\n",
       " 'KRISHNARAJA SAGARA',\n",
       " 'LINGANAMAKKI',\n",
       " 'LOWER BHAWANI',\n",
       " 'LOWER MANAIR',\n",
       " 'MACHCHHU-I',\n",
       " 'MACHCHHU-II',\n",
       " 'MACHKUND(JALAPUT)',\n",
       " 'MAHANADI',\n",
       " 'MAHI BAJAJ SAGAR',\n",
       " 'MAITHON',\n",
       " 'MALAMPUZHA',\n",
       " 'MALAPRABHA(RENUKA)',\n",
       " 'MANDIRA DAM',\n",
       " 'MANI DAM',\n",
       " 'MANIKDOH',\n",
       " 'MATATILA',\n",
       " 'MAUDAHA',\n",
       " 'MAYURAKSHI',\n",
       " 'MEJA',\n",
       " 'METTUR(STANLEY)',\n",
       " 'MINIMATA BANGO',\n",
       " 'MULA',\n",
       " 'MULSHI',\n",
       " 'MUSI PROJECT',\n",
       " 'NAGARJUNA SAGAR',\n",
       " 'NANAK SAGAR',\n",
       " 'NARAYANPUR',\n",
       " 'NIRA DEOGHAR',\n",
       " 'NIZAM SAGAR',\n",
       " 'OMKARESHWAR',\n",
       " 'PANAM',\n",
       " 'PANCHET HILL',\n",
       " 'PANSHET(TANAJISAGAR)',\n",
       " 'PARAMBIKULAM',\n",
       " 'PENCH(TOTLADOH)',\n",
       " 'PERIYAR',\n",
       " 'PONG DAM(BEAS)',\n",
       " 'PRIYADARSHINI JURALA',\n",
       " 'RAJGHAT DAM',\n",
       " 'RAMGANGA',\n",
       " 'RANA PRATAP SAGAR',\n",
       " 'RANGAWAN',\n",
       " 'RENGALI',\n",
       " 'RIHAND',\n",
       " 'SABARMATI(DHAROI)',\n",
       " 'SALANADI',\n",
       " 'SANJAY SAROVAR',\n",
       " 'SAPUA',\n",
       " 'SARDAR SAROVAR',\n",
       " 'SATHANUR',\n",
       " 'SHARDA SAGAR',\n",
       " 'SHETRUNJI',\n",
       " 'SHOLAYAR',\n",
       " 'SINGUR',\n",
       " 'SIRSI',\n",
       " 'SOMASILA',\n",
       " 'SRIRAMSAGAR',\n",
       " 'SRISAILAM',\n",
       " 'SUKHI(GUJ)',\n",
       " 'SUPA',\n",
       " 'SURYA',\n",
       " 'TANDULA',\n",
       " 'TATTIHALLA',\n",
       " 'TAWA',\n",
       " 'TEHRI',\n",
       " 'TENUGHAT',\n",
       " 'THEIN DAM',\n",
       " 'THOKARWADI',\n",
       " 'TILAIYA',\n",
       " 'TILLARI',\n",
       " 'TUNGABHADRA',\n",
       " 'UKAI',\n",
       " 'UMRONG',\n",
       " 'UND-I',\n",
       " 'UPPER INDRAVATI',\n",
       " 'UPPER KOLAB',\n",
       " 'UPPER TAPI',\n",
       " 'UPPER VAITARNA',\n",
       " 'UPPER WARDHA',\n",
       " 'URMODI',\n",
       " 'VAIGAI',\n",
       " 'VANI VILAS SAGAR',\n",
       " 'VEER DAM',\n",
       " 'WATRAK',\n",
       " 'YELDARI',\n",
       " 'YELERU']"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reservoir_list = ['ALIYAR',\n",
    " 'ALMATTI',\n",
    " 'ATAL SAGAR(MADIKHEDA)',\n",
    " 'BALIMELA',\n",
    " 'BANSAGAR',\n",
    " 'BARGI',\n",
    " 'BARNA DAM',\n",
    " 'BARVI DAM',\n",
    " 'BHADAR',\n",
    " 'BHADRA',\n",
    " 'BHAMA ASKHED',\n",
    " 'BHANDARDARA',\n",
    " 'BHATGHAR',\n",
    " 'BHATSA',\n",
    " 'BHIMA(UJJANI)',\n",
    " 'BISALPUR',\n",
    " 'BRAHMANI(GUJ)',\n",
    " 'CHANDAN DAM',\n",
    " 'CHASKAMAN',\n",
    " 'DAMANGANGA',\n",
    " 'DANTIWADA',\n",
    " 'DARNA DAM',\n",
    " 'DHOM',\n",
    " 'DIMBHE DAM',\n",
    " 'DONKARAYI',\n",
    " 'DOYANG HEP',\n",
    " 'DUDHAWA',\n",
    " 'DUDHGANGA',\n",
    " 'GANDHI SAGAR',\n",
    " 'GERUSOPPA',\n",
    " 'GETALSUD',\n",
    " 'GHATAPRABHA(HIDKAL)',\n",
    " 'GIRNA',\n",
    " 'GOBIND SAGAR(BHAKRA)',\n",
    " 'GUMTI',\n",
    " 'HARANGI',\n",
    " 'HARIHARJHOR',\n",
    " 'HATHMATI',\n",
    " 'HEMAVATHY',\n",
    " 'HIRAKUD',\n",
    " 'IDAMALAYAR',\n",
    " 'IDUKKI',\n",
    " 'INDIRA SAGAR',\n",
    " 'ISAPUR',\n",
    " 'JAISAMAND',\n",
    " 'JAWAI DAM',\n",
    " 'JAYAKWADI(PAITHAN)',\n",
    " 'JHAKAM',\n",
    " 'JIRGO',\n",
    " 'KABINI',\n",
    " 'KADANA',\n",
    " 'KADDAM (K.N.R.)',\n",
    " 'KAKKI',\n",
    " 'KALLADA(PARAPPAR)',\n",
    " 'KANDALERU',\n",
    " 'KANGSABATI',\n",
    " 'KANHER',\n",
    " 'KARJAN',\n",
    " 'KHADAKVASLA',\n",
    " 'KHANDONG',\n",
    " 'KOL DAM',\n",
    " 'KOLAR DAM',\n",
    " 'KONAR',\n",
    " 'KOYANA',\n",
    " 'KRISHNARAJA SAGARA',\n",
    " 'LINGANAMAKKI',\n",
    " 'LOWER BHAWANI',\n",
    " 'LOWER MANAIR',\n",
    " 'MACHCHHU-I',\n",
    " 'MACHCHHU-II',\n",
    " 'MACHKUND(JALAPUT)',\n",
    " 'MAHANADI',\n",
    " 'MAHI BAJAJ SAGAR',\n",
    " 'MAITHON',\n",
    " 'MALAMPUZHA',\n",
    " 'MALAPRABHA(RENUKA)',\n",
    " 'MANDIRA DAM',\n",
    " 'MANI DAM',\n",
    " 'MANIKDOH',\n",
    " 'MATATILA',\n",
    " 'MAUDAHA',\n",
    " 'MAYURAKSHI',\n",
    " 'MEJA',\n",
    " 'METTUR(STANLEY)',\n",
    " 'MINIMATA BANGO',\n",
    " 'MULA',\n",
    " 'MULSHI',\n",
    " 'MUSI PROJECT',\n",
    " 'NAGARJUNA SAGAR',\n",
    " 'NANAK SAGAR',\n",
    " 'NARAYANPUR',\n",
    " 'NIRA DEOGHAR',\n",
    " 'NIZAM SAGAR',\n",
    " 'OMKARESHWAR',\n",
    " 'PANAM',\n",
    " 'PANCHET HILL',\n",
    " 'PANSHET(TANAJISAGAR)',\n",
    " 'PARAMBIKULAM',\n",
    " 'PENCH(TOTLADOH)',\n",
    " 'PERIYAR',\n",
    " 'PONG DAM(BEAS)',\n",
    " 'PRIYADARSHINI JURALA',\n",
    " 'RAJGHAT DAM',\n",
    " 'RAMGANGA',\n",
    " 'RANA PRATAP SAGAR',\n",
    " 'RANGAWAN',\n",
    " 'RENGALI',\n",
    " 'RIHAND',\n",
    " 'SABARMATI(DHAROI)',\n",
    " 'SALANADI',\n",
    " 'SANJAY SAROVAR',\n",
    " 'SAPUA',\n",
    " 'SARDAR SAROVAR',\n",
    " 'SATHANUR',\n",
    " 'SHARDA SAGAR',\n",
    " 'SHETRUNJI',\n",
    " 'SHOLAYAR',\n",
    " 'SINGUR',\n",
    " 'SIRSI',\n",
    " 'SOMASILA',\n",
    " 'SRIRAMSAGAR',\n",
    " 'SRISAILAM',\n",
    " 'SUKHI(GUJ)',\n",
    " 'SUPA',\n",
    " 'SURYA',\n",
    " 'TANDULA',\n",
    " 'TATTIHALLA',\n",
    " 'TAWA',\n",
    " 'TEHRI',\n",
    " 'TENUGHAT',\n",
    " 'THEIN DAM',\n",
    " 'THOKARWADI',\n",
    " 'TILAIYA',\n",
    " 'TILLARI',\n",
    " 'TUNGABHADRA',\n",
    " 'UKAI',\n",
    " 'UMRONG',\n",
    " 'UND-I',\n",
    " 'UPPER INDRAVATI',\n",
    " 'UPPER KOLAB',\n",
    " 'UPPER TAPI',\n",
    " 'UPPER VAITARNA',\n",
    " 'UPPER WARDHA',\n",
    " 'URMODI',\n",
    " 'VAIGAI',\n",
    " 'VANI VILAS SAGAR',\n",
    " 'VEER DAM',\n",
    " 'WATRAK',\n",
    " 'YELDARI',\n",
    " 'YELERU']\n",
    "\n",
    "reservoir_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finding Latitude and Longitude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install geopy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from geopy.geocoders import Nominatim\n",
    "from time import sleep\n",
    "\n",
    "geolocator = Nominatim(user_agent=\"reservoir_locator\")\n",
    "\n",
    "# Function to get latitude and longitude\n",
    "def get_lat_long(reservoir_name):\n",
    "    try:\n",
    "        location = geolocator.geocode(reservoir_name)\n",
    "        if location:\n",
    "            return location.latitude, location.longitude\n",
    "        else:\n",
    "            return None, None\n",
    "    except:\n",
    "        return None, None\n",
    "\n",
    "# List to store data\n",
    "data = []\n",
    "\n",
    "# Get coordinates for each reservoir\n",
    "for reservoir in reservoir_list:\n",
    "    lat, longitude = get_lat_long(reservoir)\n",
    "    data.append([reservoir, lat, longitude])\n",
    "    sleep(1)  # To prevent overwhelming the geocoding service\n",
    "# Create DataFrame\n",
    "df = pd.DataFrame(data, columns=[\"NAME OF RESERVOIR\", \"Latitude\", \"Longitude\"])\n",
    "df.to_csv(\"./lat-long.csv\",index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RUN CODE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rf reservoir_data final_reservoir_data weekwise_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seperating the reservoir data and creating unique files\n",
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "\n",
    "csv_folder = \"./excel-dir\"\n",
    "output_folder = \"reservoir_data\"\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "# Load latitude and longitude data\n",
    "lat_long_df = pd.read_csv(\"./lat-long.csv\")  # Assuming columns are 'NAME OF RESERVOIR', 'Latitude', 'Longitude'\n",
    "\n",
    "for filename in os.listdir(csv_folder):\n",
    "    if filename.endswith(\".csv\"):\n",
    "        filepath = os.path.join(csv_folder, filename)\n",
    "        df = pd.read_csv(filepath)\n",
    "        df['DATE'] = pd.to_datetime(df['DATE'], format='%d-%m-%Y')\n",
    "\n",
    "        for reservoir in reservoir_list:\n",
    "            reservoir_data = df[df[\"NAME OF RESERVOIR\"] == reservoir].copy()\n",
    "            reservoir_data.sort_values(by=\"DATE\", inplace=True)\n",
    "            reservoir_data.drop(columns=[\"S. NO\"], inplace=True)  \n",
    "\n",
    "            if not reservoir_data.empty:\n",
    "                reservoir_data = reservoir_data.merge(\n",
    "                    lat_long_df, on=\"NAME OF RESERVOIR\", how=\"left\"\n",
    "                )\n",
    "\n",
    "                cleaned_name = re.sub(r'[.\\s]+', '', reservoir) \n",
    "                output_path = os.path.join(output_folder, f\"{cleaned_name}.csv\")\n",
    "\n",
    "                if os.path.exists(output_path):\n",
    "                    reservoir_data.to_csv(output_path, mode='a', header=False, index=False)\n",
    "                else:\n",
    "                    reservoir_data.to_csv(output_path, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding weeks\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "reservoir_dir = \"./reservoir_data\"\n",
    "updated_reservoir_data = \"./final_reservoir_data\"\n",
    "\n",
    "os.makedirs(updated_reservoir_data, exist_ok=True)\n",
    "\n",
    "for filename in os.listdir(reservoir_dir):\n",
    "    filepath = os.path.join(reservoir_dir, filename)\n",
    "    outputPath = os.path.join(updated_reservoir_data, filename)\n",
    "\n",
    "    df = pd.read_csv(filepath)\n",
    "    df['DATE'] = pd.to_datetime(df['DATE'])\n",
    "    df['WEEK'] = df['DATE'].dt.isocalendar().week\n",
    "\n",
    "    # Get the reservoir name \n",
    "    reservoir_name = df['NAME OF RESERVOIR'].iloc[0]\n",
    "    latitude = df[\"Latitude\"].iloc[0]\n",
    "    longitude = df[\"Longitude\"].iloc[0]\n",
    "\n",
    "    # Calculate weekly mean and std dev of \"RESERVOIR LEVEL (m)\"\n",
    "    weekly_stats = df.groupby('WEEK')['RESERVOIR LEVEL (m)'].agg(['mean', 'std']).reset_index()\n",
    "\n",
    "    # Rename columns for clarity\n",
    "\n",
    "    # Add the reservoir name column\n",
    "    weekly_stats.columns = ['WEEK', 'MEAN', 'STD']\n",
    "    weekly_stats['NAME OF RESERVOIR'] = reservoir_name\n",
    "    weekly_stats['Latitude'] = latitude\n",
    "    weekly_stats['Longitude'] = longitude\n",
    "\n",
    "    # Save the resulting DataFrame to a new CSV file\n",
    "    weekly_stats.to_csv(outputPath, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seperating Weekly Data\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "final_reservoir_data = \"./final_reservoir_data\"\n",
    "weekly_reservoir_data = \"./weekwise_data\"\n",
    "\n",
    "os.makedirs(weekly_reservoir_data, exist_ok=True)\n",
    "\n",
    "columns_to_keep = ['NAME OF RESERVOIR', 'Latitude', 'Longitude', 'MEAN', 'STD']\n",
    "\n",
    "for week in range(1, 54):\n",
    "    outPath = os.path.join(weekly_reservoir_data, f\"{week}.csv\")\n",
    "\n",
    "    # Create a new empty DataFrame for each week\n",
    "    weekly_df = pd.DataFrame(columns=columns_to_keep)\n",
    "\n",
    "    # Flag to check if the header has been written\n",
    "    header_written = False \n",
    "\n",
    "    for filename in os.listdir(final_reservoir_data):\n",
    "        filepath = os.path.join(final_reservoir_data, filename)\n",
    "        df = pd.read_csv(filepath)\n",
    "\n",
    "        week_data = df[df['WEEK'] == week][columns_to_keep]\n",
    "\n",
    "        # Append data to the weekly DataFrame\n",
    "        weekly_df = pd.concat([weekly_df, week_data])\n",
    "        # Write header only once for each week file\n",
    "        if not header_written and not week_data.empty:\n",
    "            weekly_df.to_csv(outPath, mode='a', header=True, index=False)\n",
    "            header_written = True\n",
    "        else:\n",
    "            week_data.to_csv(outPath, mode='a', header=False, index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "for filename in os.listdir(\"weekwise_data\"):\n",
    "    filepath = os.path.join(\"weekwise_data\", filename)\n",
    "\n",
    "    df = pd.read_csv(filepath)\n",
    "    df.sort_values(by=\"NAME OF RESERVOIR\", inplace=True)\n",
    "\n",
    "    # Overwrite the existing CSV file with the sorted data\n",
    "    df.to_csv(filepath, index=False) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making new data workable\n",
    "import re\n",
    "import csv\n",
    "\n",
    "column_names = [\n",
    "    \"S. NO\", \"NAME OF RESERVOIR\", \"FRL (m)\", \"RESERVOIR LEVEL (m)\", \"LIVE CAPACITY AT FRL (BCM)\", \n",
    "    \"CURRENT LIVE STORAGE (BCM)\", \"DATE\", \"CURRENT YEAR\", \"LAST YEAR\", \"LAST 10 YEARS AVERAGE\", \n",
    "    \"IRR. (CCA) IN TH. HA\", \"HYDEL IN MW\"\n",
    "]\n",
    "pattern = re.compile(\n",
    "    r'^([*,&,#,@,!,$,%,^,(,),_,+]*\\d+)\\s+(.+?)\\s+([\\d.]+)\\s+([\\d.]+)\\s+([\\d.]+)\\s+([\\d.]+)\\s+(\\d{2}-\\d{2}-\\d{2,4})\\s+([\\d.]+|\\s+)\\s+([\\d.]+|\\s+)\\s+([\\d.]+|\\s+)\\s+([\\d.-]+|\\s+)\\s+([\\d.-]+|\\s+)'\n",
    ")\n",
    "\n",
    "extracted_lines = []\n",
    "with open(\"newdata.txt\", 'r') as file:\n",
    "        lines = file.readlines()\n",
    "        for line in lines:\n",
    "            match = pattern.match(line)\n",
    "            if match:\n",
    "                extracted_lines.append(match.groups())\n",
    "with open(\"newdata.csv\", 'w', newline='') as csvfile:\n",
    "    csvwriter = csv.writer(csvfile)\n",
    "    csvwriter.writerow(column_names)\n",
    "    csvwriter.writerows(extracted_lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"newdata.csv\")\n",
    "z = True\n",
    "x = df['NAME OF RESERVOIR'].tolist()\n",
    "for i in x:\n",
    "    if i not in reservoir_list:\n",
    "        z = False\n",
    "columns_to_drop = ['S. NO', 'FRL (m)',\n",
    "       'LIVE CAPACITY AT FRL (BCM)', 'CURRENT LIVE STORAGE (BCM)', 'DATE',\n",
    "       'CURRENT YEAR', 'LAST YEAR', 'LAST 10 YEARS AVERAGE',\n",
    "       'IRR. (CCA) IN TH. HA', 'HYDEL IN MW', ]\n",
    "\n",
    "if z :\n",
    "    lat_long_df = pd.read_csv(\"lat-long.csv\")\n",
    "    df['DATE'] = pd.to_datetime(df['DATE'],format=\"%d-%m-%Y\")\n",
    "    df['WEEK'] = df['DATE'].dt.isocalendar().week\n",
    "    df.drop(columns=columns_to_drop, inplace=True)\n",
    "    df.columns = [\"NAME OF RESERVOIR\", 'CURRENT','WEEK']\n",
    "    df.to_csv(\"processed_new_data.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NAME OF RESERVOIR</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>Historical Mean</th>\n",
       "      <th>Historical STD</th>\n",
       "      <th>Current</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ALIYAR</td>\n",
       "      <td>10.462578</td>\n",
       "      <td>76.990559</td>\n",
       "      <td>307.763333</td>\n",
       "      <td>5.649870</td>\n",
       "      <td>310.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ALMATTI</td>\n",
       "      <td>16.345046</td>\n",
       "      <td>75.901225</td>\n",
       "      <td>508.220000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>517.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ATAL SAGAR(MADIKHEDA)</td>\n",
       "      <td>25.557944</td>\n",
       "      <td>77.853440</td>\n",
       "      <td>336.750000</td>\n",
       "      <td>0.282843</td>\n",
       "      <td>330.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BALIMELA</td>\n",
       "      <td>18.229661</td>\n",
       "      <td>82.063068</td>\n",
       "      <td>446.752857</td>\n",
       "      <td>4.244556</td>\n",
       "      <td>442.57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>BANSAGAR</td>\n",
       "      <td>24.189256</td>\n",
       "      <td>81.287182</td>\n",
       "      <td>335.267143</td>\n",
       "      <td>1.424766</td>\n",
       "      <td>332.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>VANI VILAS SAGAR</td>\n",
       "      <td>12.283362</td>\n",
       "      <td>76.641692</td>\n",
       "      <td>641.368333</td>\n",
       "      <td>7.581275</td>\n",
       "      <td>647.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>VEER DAM</td>\n",
       "      <td>18.132167</td>\n",
       "      <td>74.097339</td>\n",
       "      <td>573.965000</td>\n",
       "      <td>5.819489</td>\n",
       "      <td>571.13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>WATRAK</td>\n",
       "      <td>22.880856</td>\n",
       "      <td>72.844397</td>\n",
       "      <td>130.330000</td>\n",
       "      <td>2.486189</td>\n",
       "      <td>128.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144</th>\n",
       "      <td>YELDARI</td>\n",
       "      <td>19.717768</td>\n",
       "      <td>76.737603</td>\n",
       "      <td>453.787143</td>\n",
       "      <td>5.590652</td>\n",
       "      <td>454.49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>YELERU</td>\n",
       "      <td>17.739265</td>\n",
       "      <td>81.986860</td>\n",
       "      <td>77.377500</td>\n",
       "      <td>1.644169</td>\n",
       "      <td>71.27</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>146 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         NAME OF RESERVOIR   Latitude  Longitude  Historical Mean  \\\n",
       "0                   ALIYAR  10.462578  76.990559       307.763333   \n",
       "1                  ALMATTI  16.345046  75.901225       508.220000   \n",
       "2    ATAL SAGAR(MADIKHEDA)  25.557944  77.853440       336.750000   \n",
       "3                 BALIMELA  18.229661  82.063068       446.752857   \n",
       "4                 BANSAGAR  24.189256  81.287182       335.267143   \n",
       "..                     ...        ...        ...              ...   \n",
       "141       VANI VILAS SAGAR  12.283362  76.641692       641.368333   \n",
       "142               VEER DAM  18.132167  74.097339       573.965000   \n",
       "143                 WATRAK  22.880856  72.844397       130.330000   \n",
       "144                YELDARI  19.717768  76.737603       453.787143   \n",
       "145                 YELERU  17.739265  81.986860        77.377500   \n",
       "\n",
       "     Historical STD  Current  \n",
       "0          5.649870   310.04  \n",
       "1          0.000000   517.01  \n",
       "2          0.282843   330.45  \n",
       "3          4.244556   442.57  \n",
       "4          1.424766   332.30  \n",
       "..              ...      ...  \n",
       "141        7.581275   647.30  \n",
       "142        5.819489   571.13  \n",
       "143        2.486189   128.16  \n",
       "144        5.590652   454.49  \n",
       "145        1.644169    71.27  \n",
       "\n",
       "[146 rows x 6 columns]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating mapping_data.csv with historical mean and current data\n",
    "import pandas as pd\n",
    "\n",
    "new_df = pd.read_csv(\"processed_new_data.csv\")\n",
    "week = new_df[\"WEEK\"][0]\n",
    "\n",
    "historical_df = pd.read_csv(f\"./weekwise_data/{week}.csv\")\n",
    "\n",
    "map_df = historical_df.merge(new_df, on=\"NAME OF RESERVOIR\", how=\"left\")\n",
    "map_df.drop(columns=\"WEEK\", inplace=True)\n",
    "map_df.columns = ['NAME OF RESERVOIR', 'Latitude', 'Longitude', 'Historical Mean','Historical STD',\n",
    "       'Current']\n",
    "map_df['Historical STD'].fillna(0, inplace=True)\n",
    "map_df.to_csv(\"map_data.csv\", index=False)\n",
    "map_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping KOYANA due to missing location data\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import folium\n",
    "from folium.plugins import FeatureGroupSubGroup\n",
    "import branca\n",
    "\n",
    "# Load reservoir data from CSV\n",
    "df = pd.read_csv(\"map_data.csv\")\n",
    "\n",
    "reservoir_data = {}\n",
    "for index, row in df.iterrows():\n",
    "    reservoir_name = row[\"NAME OF RESERVOIR\"]\n",
    "    latitude = row[\"Latitude\"]\n",
    "    longitude = row[\"Longitude\"]\n",
    "    if pd.isna(latitude) or pd.isna(longitude):\n",
    "        print(f\"Skipping {reservoir_name} due to missing location data\")\n",
    "        continue\n",
    "\n",
    "    current_level = row['Current']\n",
    "    historical_mean = row['Historical Mean']\n",
    "    historical_std = row['Historical STD']\n",
    "    z_score = 0 if historical_std == 0 else (current_level - historical_mean) / historical_std\n",
    "    anomaly = \"Low\" if z_score < -1 else \"High\" if z_score > 1 else \"Normal\"\n",
    "    reservoir_data[reservoir_name] = {\n",
    "        'Latitude': latitude,\n",
    "        'Longitude': longitude,\n",
    "        'RESERVOIR LEVEL (m)': current_level,\n",
    "        'Anomaly': anomaly,\n",
    "        'Z-Score': z_score\n",
    "    }\n",
    "\n",
    "center_lat = sum(data['Latitude'] for data in reservoir_data.values()) / len(reservoir_data)\n",
    "center_lon = sum(data['Longitude'] for data in reservoir_data.values()) / len(reservoir_data)\n",
    "map_center = [center_lat, center_lon]\n",
    "\n",
    "# Create a Folium map restricted to India\n",
    "m = folium.Map(location=map_center, zoom_start=5, tiles='OpenStreetMap')\n",
    "m.fit_bounds([[8.4, 68.7], [37.6, 97.25]])  # Bounding box for India\n",
    "\n",
    "# Feature groups for filtering\n",
    "normal_group = folium.FeatureGroup(name='Normal')\n",
    "low_group = folium.FeatureGroup(name='Low')\n",
    "high_group = folium.FeatureGroup(name='High')\n",
    "\n",
    "# Add markers to the map\n",
    "for name, data in reservoir_data.items():\n",
    "    popup_content = f\"\"\"\n",
    "    <div style=\"font-size: 14px;\">\n",
    "        <b>{name}</b><br>\n",
    "        <b>Reservoir Level:</b> {data['RESERVOIR LEVEL (m)']} m<br>\n",
    "        <b>Anomaly:</b> <span style=\"color:{anomaly_colors[data['Anomaly']]}\">{data['Anomaly']}</span><br>\n",
    "        <b>Z-Score:</b> {data['Z-Score']:.2f}\n",
    "    </div>\n",
    "    \"\"\"\n",
    "    marker = folium.CircleMarker(\n",
    "        location=[data['Latitude'], data['Longitude']],\n",
    "        radius=7,\n",
    "        color=anomaly_colors[data['Anomaly']],\n",
    "        fill=True,\n",
    "        fill_color=anomaly_colors[data['Anomaly']],\n",
    "        fill_opacity=0.7,\n",
    "        popup=folium.Popup(popup_content, max_width=300)\n",
    "    )\n",
    "    if data['Anomaly'] == 'Normal':\n",
    "        normal_group.add_child(marker)\n",
    "    elif data['Anomaly'] == 'Low':\n",
    "        low_group.add_child(marker)\n",
    "    elif data['Anomaly'] == 'High':\n",
    "        high_group.add_child(marker)\n",
    "\n",
    "m.add_child(normal_group)\n",
    "m.add_child(low_group)\n",
    "m.add_child(high_group)\n",
    "\n",
    "# Add a layer control\n",
    "folium.LayerControl(collapsed=False).add_to(m)\n",
    "\n",
    "# Add a legend\n",
    "legend_html = '''\n",
    "     <div style=\"position: fixed; \n",
    "     bottom: 50px; left: 50px; width: 150px; height: 120px; \n",
    "     border:2px solid grey; z-index:9999; font-size:14px;\n",
    "     background-color:white; opacity: 0.8;\">\n",
    "     &nbsp; <b>Legend</b> <br>\n",
    "     &nbsp; <i class=\"fa fa-circle\" style=\"color:green\"></i> Normal<br>\n",
    "     &nbsp; <i class=\"fa fa-circle\" style=\"color:red\"></i> Low<br>\n",
    "     &nbsp; <i class=\"fa fa-circle\" style=\"color:blue\"></i> High<br>\n",
    "     </div>\n",
    "     '''\n",
    "m.get_root().html.add_child(folium.Element(legend_html))\n",
    "\n",
    "# Save the map\n",
    "m.save('index.html')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
