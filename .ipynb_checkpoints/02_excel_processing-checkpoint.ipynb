{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import os\n",
    "import keyboard\n",
    "\n",
    "final_text_dir = \"./processed_text\"\n",
    "text_dir = \"./text\"\n",
    "\n",
    "os.makedirs(final_text_dir, exist_ok=True)\n",
    "\n",
    "for idx, filename in enumerate(os.listdir(text_dir)):\n",
    "    filepath = os.path.join(text_dir, filename)\n",
    "    new_lines = []\n",
    "    writePath = os.path.join(final_text_dir, filename)\n",
    "\n",
    "    with open(filepath, 'r') as file:\n",
    "        lines = file.readlines()\n",
    "    \n",
    "    for index,line in enumerate(lines):\n",
    "        # os.system('cls' if os.name == 'nt' else 'clear')\n",
    "        print(f\"{line.strip()}\")\n",
    "        while True:\n",
    "                if keyboard.is_pressed('y'):\n",
    "                    print(\"Deleted\")\n",
    "                    break\n",
    "                elif keyboard.is_pressed('n'):\n",
    "                    new_lines.append(line)\n",
    "                    print(\"Kept\")\n",
    "                    break\n",
    "    with open(writePath, 'w') as file:\n",
    "        file.writelines(new_lines)\n",
    "    if(idx == 0):\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "import csv\n",
    "\n",
    "column_names = [\n",
    "    \"S. NO\", \"NAME OF RESERVOIR\", \"FRL (m)\", \"RESERVOIR LEVEL (m)\", \"LIVE CAPACITY AT FRL (BCM)\", \n",
    "    \"CURRENT LIVE STORAGE (BCM)\", \"DATE\", \"CURRENT YEAR\", \"LAST YEAR\", \"LAST 10 YEARS AVERAGE\", \n",
    "    \"IRR. (CCA) IN TH. HA\", \"HYDEL IN MW\"\n",
    "]\n",
    "\n",
    "txt_folder = \"./text\"\n",
    "excel_output = \"./excel-dir\"\n",
    "os.makedirs(excel_output, exist_ok=True)\n",
    "\n",
    "# pattern = re.compile(\n",
    "#     r'^\\*?(\\d+)\\s+([A-Z\\(\\)a-z\\s]+)\\s+([\\d.]+)\\s+([\\d.]+)\\s+([\\d.]+)\\s+([\\d.]+)\\s+(\\d{2}-\\d{2}-\\d{4})\\s+([\\d.]+)\\s+([\\d.]+)\\s+([\\d.]+)\\s+([\\d.-]+)\\s+([\\d.-]+)'\n",
    "# )\n",
    "\n",
    "pattern = re.compile(\n",
    "    r'(\\d+)\\s+(.+?)\\s+([\\d.]+)\\s+([\\d.]+)\\s+([\\d.]+)\\s+([\\d.]+)\\s+(\\d{2}-\\d{2}-\\d{4})\\s+([\\d.]+|\\s+)\\s+([\\d.]+|\\s+)\\s+([\\d.]+|\\s+)\\s+([\\d.-]+|\\s+)\\s+([\\d.-]+|\\s+)'\n",
    ")\n",
    "\n",
    "for idx,filename in enumerate(os.listdir(txt_folder)):\n",
    "    # if(idx>0):\n",
    "    #     break\n",
    "    filepath = os.path.join(txt_folder, filename)\n",
    "    excelpath = os.path.join(excel_output, filename.replace(\".txt\",\".csv\"))\n",
    "    extracted_lines = []\n",
    "    with open(filepath, 'r') as file:\n",
    "            lines = file.readlines()\n",
    "            for line in lines:\n",
    "                match = pattern.match(line)\n",
    "                if match:\n",
    "                    extracted_lines.append(match.groups())\n",
    "    with open(excelpath, 'w', newline='') as csvfile:\n",
    "        csvwriter = csv.writer(csvfile)\n",
    "        csvwriter.writerow(column_names)\n",
    "        csvwriter.writerows(extracted_lines)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "csv_folder = \"./excel-dir\"\n",
    "unique_reservoirs = set()\n",
    "\n",
    "for filename in os.listdir(csv_folder):\n",
    "    if filename.endswith(\".csv\"):\n",
    "        filepath = os.path.join(csv_folder, filename)\n",
    "        df = pd.read_csv(filepath)\n",
    "        reservoir_names = df[\"NAME OF RESERVOIR\"].astype(str)  # Convert to string to handle mixed data types\n",
    "\n",
    "        for name in reservoir_names:\n",
    "            # Remove numbers, parentheses, and excess spaces\n",
    "            cleaned_name = re.sub(r'[0-9()]+', '', name).strip()  \n",
    "            if cleaned_name:  # Add only if the cleaned name is not empty\n",
    "                unique_reservoirs.add(cleaned_name)\n",
    "\n",
    "print(\"Unique reservoir names found (excluding numbers):\")\n",
    "display(len(unique_reservoirs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_reservoirs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reservoir_list = [\n",
    "    \"GOBIND SAGAR(BHAKRA)\",\n",
    "    \"PONG DAM(BEAS)\",\n",
    "    \"KOL DAM\",\n",
    "    \"THEIN DAM\",\n",
    "    \"MAHI BAJAJ SAGAR\",\n",
    "    \"JHAKAM\",\n",
    "    \"RANA PRATAP SAGAR\",\n",
    "    \"BISALPUR\",\n",
    "    \"JAWAI DAM\",\n",
    "    \"JAISAMAND\",\n",
    "    \"TENUGHAT\",\n",
    "    \"MAITHON\",\n",
    "    \"PANCHET HILL\",\n",
    "    \"KONAR\",\n",
    "    \"TILAIYA\",\n",
    "    \"GETALSUD\",\n",
    "    \"HIRAKUD\",\n",
    "    \"BALIMELA\",\n",
    "    \"SALANADI\",\n",
    "    \"RENGALI\",\n",
    "    \"MACHKUND(JALAPUT)\",\n",
    "    \"UPPER KOLAB\",\n",
    "    \"UPPER INDRAVATI\",\n",
    "    \"SAPUA\",\n",
    "    \"HARIHARJHOR\",\n",
    "    \"MANDIRA DAM\",\n",
    "    \"MAYURAKSHI\",\n",
    "    \"KANGSABATI\",\n",
    "    \"GUMTI\",\n",
    "    \"DOYANG HEP\",\n",
    "    \"CHANDAN DAM\",\n",
    "    \"UMRONG\",\n",
    "    \"KHANDONG\",\n",
    "    \"UKAI\",\n",
    "    \"SABARMATI(DHAROI)\",\n",
    "    \"KADANA\",\n",
    "    \"SHETRUNJI\",\n",
    "    \"BHADAR\",\n",
    "    \"DAMANGANGA\",\n",
    "    \"DANTIWADA\",\n",
    "    \"PANAM\",\n",
    "    \"SARDAR SAROVAR\",\n",
    "    \"KARJAN\",\n",
    "    \"SUKHI(GUJ)\",\n",
    "    \"WATRAK\",\n",
    "    \"HATHMATI\",\n",
    "    \"MACHCHHU-I\",\n",
    "    \"MACHCHHU-II\",\n",
    "    \"UND-I\",\n",
    "    \"BRAHMANI(GUJ)\",\n",
    "    \"JAYAKWADI(PAITHAN)\",\n",
    "    \"KOYANA\",\n",
    "    \"BHIMA(UJJANI)\",\n",
    "    \"ISAPUR\",\n",
    "    \"MULA\",\n",
    "    \"YELDARI\",\n",
    "    \"GIRNA\",\n",
    "    \"KHADAKVASLA\",\n",
    "    \"UPPER VAITARNA\",\n",
    "    \"UPPER TAPI\",\n",
    "    \"PENCH(TOTLADOH)\",\n",
    "    \"UPPER WARDHA\",\n",
    "    \"BHATSA\",\n",
    "    \"DHOM\",\n",
    "    \"DUDHGANGA\",\n",
    "    \"MANIKDOH\",\n",
    "    \"BHANDARDARA\",\n",
    "    \"URMODI\",\n",
    "    \"BHATGHAR\",\n",
    "    \"NIRA DEOGHAR\",\n",
    "    \"THOKARWADI\",\n",
    "    \"KANHER\",\n",
    "    \"MULSHI\",\n",
    "    \"SURYA\",\n",
    "    \"TILLARI\",\n",
    "    \"DIMBHE DAM\",\n",
    "    \"VEER DAM\",\n",
    "    \"BARVI DAM\",\n",
    "    \"CHASKAMAN\",\n",
    "    \"PANSHET(TANAJISAGAR)\",\n",
    "    \"BHAMA ASKHED\",\n",
    "    \"DARNA DAM\",\n",
    "    \"MATATILA\",\n",
    "    \"RIHAND\",\n",
    "    \"SHARDA SAGAR\",\n",
    "    \"SIRSI\",\n",
    "    \"MAUDAHA\",\n",
    "    \"JIRGO\",\n",
    "    \"RANGAWAN\",\n",
    "    \"MEJA\",\n",
    "    \"RAMGANGA\",\n",
    "    \"TEHRI\",\n",
    "    \"NANAK SAGAR\",\n",
    "    \"GANDHI SAGAR\",\n",
    "    \"TAWA\",\n",
    "    \"BARGI\",\n",
    "    \"BANSAGAR\",\n",
    "    \"INDIRA SAGAR\",\n",
    "    \"BARNA DAM\",\n",
    "    \"OMKARESHWAR\",\n",
    "    \"SANJAY SAROVAR\",\n",
    "    \"RAJGHAT DAM\",\n",
    "    \"KOLAR DAM\",\n",
    "    \"ATAL SAGAR(MADIKHEDA)\",\n",
    "    \"MINIMATA BANGO\",\n",
    "    \"MAHANADI\",\n",
    "    \"DUDHAWA\",\n",
    "    \"TANDULA\",\n",
    "    \"SRISAILAM\",\n",
    "    \"NAGARJUNA SAGAR\",\n",
    "    \"SOMASILA\",\n",
    "    \"YELERU\",\n",
    "    \"KANDALERU\",\n",
    "    \"DONKARAYI\",\n",
    "    \"SRIRAMSAGAR\",\n",
    "    \"LOWER MANAIR\",\n",
    "    \"NIZAM SAGAR\",\n",
    "    \"SINGUR\",\n",
    "    \"PRIYADARSHINI JURALA\",\n",
    "    \"MUSI PROJECT\",\n",
    "    \"KADDAM (K.N.R.)\",\n",
    "    \"KRISHNARAJA SAGARA\",\n",
    "    \"TUNGABHADRA\",\n",
    "    \"GHATAPRABHA(HIDKAL)\",\n",
    "    \"BHADRA\",\n",
    "    \"LINGANAMAKKI\",\n",
    "    \"NARAYANPUR\",\n",
    "    \"MALAPRABHA(RENUKA)\",\n",
    "    \"KABINI\",\n",
    "    \"HEMAVATHY\",\n",
    "    \"HARANGI\",\n",
    "    \"SUPA\",\n",
    "    \"VANI VILAS SAGAR\",\n",
    "    \"ALMATTI\",\n",
    "    \"GERUSOPPA\",\n",
    "    \"MANI DAM\",\n",
    "    \"TATTIHALLA\",\n",
    "    \"KALLADA(PARAPPAR)\",\n",
    "    \"IDAMALAYAR\",\n",
    "    \"IDUKKI\",\n",
    "    \"KAKKI\",\n",
    "    \"PERIYAR\",\n",
    "    \"MALAMPUZHA\",\n",
    "    \"LOWER BHAWANI\",\n",
    "    \"METTUR(STANLEY)\",\n",
    "    \"VAIGAI\",\n",
    "    \"PARAMBIKULAM\",\n",
    "    \"ALIYAR\",\n",
    "    \"SHOLAYAR\",\n",
    "    \"SATHANUR\"\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "csv_dir = \"./excel-dir\"\n",
    "\n",
    "for filename in os.listdir(csv_dir):\n",
    "    filepath = os.path.join(csv_dir, filename)\n",
    "    df = pd.read_csv(filepath)\n",
    "    original_names = df[\"NAME OF RESERVOIR\"]\n",
    "    for original_name in original_names:\n",
    "        matches = [name for name in reservoir_list if re.search(name, original_name, re.IGNORECASE)]\n",
    "        if matches:\n",
    "            closest_match = matches[0]  # Take the first match if there are multiple\n",
    "            df[\"NAME OF RESERVOIR\"] = df[\"NAME OF RESERVOIR\"].replace(original_name,closest_match)\n",
    "    df.to_csv(filepath, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finding Latitude and Longitude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from geopy.geocoders import Nominatim\n",
    "from time import sleep\n",
    "\n",
    "geolocator = Nominatim(user_agent=\"reservoir_locator\")\n",
    "\n",
    "# Function to get latitude and longitude\n",
    "def get_lat_long(reservoir_name):\n",
    "    try:\n",
    "        location = geolocator.geocode(reservoir_name)\n",
    "        if location:\n",
    "            return location.latitude, location.longitude\n",
    "        else:\n",
    "            return None, None\n",
    "    except:\n",
    "        return None, None\n",
    "\n",
    "# List to store data\n",
    "data = []\n",
    "\n",
    "# Get coordinates for each reservoir\n",
    "for reservoir in reservoir_list:\n",
    "    lat, long = get_lat_long(reservoir)\n",
    "    data.append([reservoir, lat, long])\n",
    "    sleep(1)  # To prevent overwhelming the geocoding service\n",
    "\n",
    "# Create DataFrame\n",
    "df = pd.DataFrame(data, columns=[\"Reservoir\", \"Latitude\", \"Longitude\"])\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"./lat-long.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install geopy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Seperating the reservoir data and creating unique files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "\n",
    "csv_folder = \"./excel-dir\"\n",
    "output_folder = \"reservoir_data\"\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "# Load latitude and longitude data\n",
    "lat_long_df = pd.read_csv(\"./lat-long.csv\")  # Assuming columns are 'NAME OF RESERVOIR', 'Latitude', 'Longitude'\n",
    "\n",
    "for filename in os.listdir(csv_folder):\n",
    "    if filename.endswith(\".csv\"):\n",
    "        filepath = os.path.join(csv_folder, filename)\n",
    "        df = pd.read_csv(filepath)\n",
    "        df['DATE'] = pd.to_datetime(df['DATE'], format='%d-%m-%Y')\n",
    "\n",
    "        for reservoir in reservoir_list:\n",
    "            reservoir_data = df[df[\"NAME OF RESERVOIR\"] == reservoir].copy()\n",
    "            reservoir_data.sort_values(by=\"DATE\", inplace=True)\n",
    "            reservoir_data.drop(columns=[\"S. NO\"], inplace=True)  \n",
    "\n",
    "            if not reservoir_data.empty:\n",
    "                reservoir_data = reservoir_data.merge(\n",
    "                    lat_long_df, on=\"NAME OF RESERVOIR\", how=\"left\"\n",
    "                )\n",
    "\n",
    "                cleaned_name = re.sub(r'[.\\s]+', '', reservoir) \n",
    "                output_path = os.path.join(output_folder, f\"{cleaned_name}.csv\")\n",
    "\n",
    "                if os.path.exists(output_path):\n",
    "                    reservoir_data.to_csv(output_path, mode='a', header=False, index=False)\n",
    "                else:\n",
    "                    reservoir_data.to_csv(output_path, index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating map for each reservoir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import folium\n",
    "import os\n",
    "import re\n",
    "\n",
    "reservoir_data_dir = \"./reservoir_data\"\n",
    "html_dir = \"./html\"\n",
    "os.makedirs(html_dir, exist_ok=True)\n",
    "\n",
    "for filename in os.listdir(reservoir_data_dir):\n",
    "    filepath = os.path.join(reservoir_data_dir, filename)\n",
    "    htmlpath = os.path.join(html_dir, filename.replace(\".csv\",\".html\"))\n",
    "    reservoir_df = pd.read_csv(filepath)\n",
    "\n",
    "    india_center = [20.5937, 78.9629]  \n",
    "    m = folium.Map(location=india_center, zoom_start=5)\n",
    "    dates = reservoir_df['DATE'].unique()\n",
    "    feature_groups = {}\n",
    "    for date in dates:\n",
    "        feature_groups[date] = folium.FeatureGroup(name=date)\n",
    "\n",
    "    for index, row in reservoir_df.iterrows():\n",
    "        reservoir_name = row['NAME OF RESERVOIR']\n",
    "        latitude = row['Latitude']\n",
    "        longitude = row['Longitude']\n",
    "        date = row['DATE']\n",
    "\n",
    "        marker = folium.Marker(\n",
    "            location=[latitude, longitude],\n",
    "            popup=f\"{reservoir_name} - {date}\",\n",
    "            icon=folium.Icon(color='blue', icon='tint')  # Customize the marker\n",
    "        )\n",
    "        \n",
    "        feature_groups[date].add_child(marker)\n",
    "    for date, feature_group in feature_groups.items():\n",
    "        m.add_child(feature_group)\n",
    "    folium.LayerControl().add_to(m)\n",
    "    m.save(htmlpath)\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import folium\n",
    "from folium.plugins import TimestampedGeoJson\n",
    "import os\n",
    "import json\n",
    "import re\n",
    "\n",
    "reservoir_data_dir = \"./reservoir_data\"\n",
    "html_output = \"./india_reservoirs_timeseries.html\"\n",
    "\n",
    "# Load all reservoir data\n",
    "all_reservoir_data = pd.DataFrame()\n",
    "for filename in os.listdir(reservoir_data_dir):\n",
    "    if filename.endswith(\".csv\"):\n",
    "        filepath = os.path.join(reservoir_data_dir, filename)\n",
    "        df = pd.read_csv(filepath)\n",
    "        df['DATE'] = pd.to_datetime(df['DATE'], format='%Y-%m-%d')\n",
    "        all_reservoir_data = pd.concat([all_reservoir_data, df])\n",
    "\n",
    "# Initialize map\n",
    "india_center = [20.5937, 78.9629]\n",
    "m = folium.Map(location=india_center, zoom_start=5)\n",
    "\n",
    "# Create a list to hold GeoJSON features\n",
    "features = []\n",
    "\n",
    "# Iterate through all reservoir data\n",
    "for index, row in all_reservoir_data.iterrows():\n",
    "    reservoir_name = row['NAME OF RESERVOIR']\n",
    "    latitude = row['Latitude']\n",
    "    longitude = row['Longitude']\n",
    "    date = row['DATE']\n",
    "    level = row['RESERVOIR LEVEL (m)']\n",
    "\n",
    "    if pd.isna(latitude) or pd.isna(longitude):\n",
    "        print(f\"Skipping {reservoir_name} on {date} due to missing coordinates.\")\n",
    "        continue\n",
    "\n",
    "    if level > 100:  # Adjust this threshold based on your data\n",
    "        icon_color = 'green'\n",
    "    elif level > 50:\n",
    "        icon_color = 'orange'\n",
    "    else:\n",
    "        icon_color = 'red'\n",
    "\n",
    "    feature = {\n",
    "        'type': 'Feature',\n",
    "        'geometry': {\n",
    "            'type': 'Point',\n",
    "            'coordinates': [longitude, latitude],\n",
    "        },\n",
    "        'properties': {\n",
    "            'time': date.strftime('%Y-%m-%d'),\n",
    "            'popup': f\"{reservoir_name}<br>Date: {date.strftime('%d-%m-%Y')}<br>Level: {level} m\",\n",
    "            'icon': 'circle',\n",
    "            'iconstyle': {\n",
    "                'color': icon_color,\n",
    "                'fillColor': icon_color,\n",
    "                'fillOpacity': 0.7,\n",
    "                'radius': 5\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "    features.append(feature)\n",
    "\n",
    "# Create a GeoJSON object for the features\n",
    "geojson = {\n",
    "    'type': 'FeatureCollection',\n",
    "    'features': features\n",
    "}\n",
    "\n",
    "# Add the TimestampedGeoJson layer to the map\n",
    "TimestampedGeoJson(\n",
    "    data=geojson,\n",
    "    transition_time=200,\n",
    "    add_last_point=True,\n",
    "    auto_play=False,\n",
    "    loop=False,\n",
    "    max_speed=100,\n",
    "    loop_button=True,\n",
    "    date_options='YYYY-MM-DD',\n",
    "    time_slider_drag_update=True\n",
    ").add_to(m)\n",
    "\n",
    "# Save the map\n",
    "m.save(html_output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import folium\n",
    "from folium.plugins import TimestampedGeoJson\n",
    "import os\n",
    "import re\n",
    "\n",
    "reservoir_data_dir = \"./reservoir_data\"\n",
    "html_output = \"./india_reservoirs_timeseries.html\"\n",
    "\n",
    "# Combine all CSV files into one DataFrame\n",
    "all_reservoir_data = pd.DataFrame()\n",
    "for filename in os.listdir(reservoir_data_dir):\n",
    "    if filename.endswith(\".csv\"):\n",
    "        filepath = os.path.join(reservoir_data_dir, filename)\n",
    "        df = pd.read_csv(filepath)\n",
    "        # Convert the DATE column to datetime64\n",
    "        df['DATE'] = pd.to_datetime(df['DATE'], format='%Y-%m-%d')\n",
    "        all_reservoir_data = pd.concat([all_reservoir_data, df])\n",
    "\n",
    "# Initialize map\n",
    "india_center = [20.5937, 78.9629]\n",
    "m = folium.Map(location=india_center, zoom_start=5)\n",
    "\n",
    "# Create a list to hold GeoJSON features\n",
    "features = []\n",
    "\n",
    "# Iterate through all reservoir data\n",
    "for index, row in all_reservoir_data.iterrows():\n",
    "    reservoir_name = row['NAME OF RESERVOIR']\n",
    "    latitude = row['Latitude']\n",
    "    longitude = row['Longitude']\n",
    "    date = row['DATE']\n",
    "    level = row['RESERVOIR LEVEL (m)']\n",
    "\n",
    "    if pd.isna(latitude) or pd.isna(longitude):\n",
    "        print(f\"Skipping {reservoir_name} on {date} due to missing coordinates.\")\n",
    "        continue\n",
    "\n",
    "    if level > 100:  # Adjust this threshold based on your data\n",
    "        icon_color = 'green'\n",
    "    elif level > 50:\n",
    "        icon_color = 'orange'\n",
    "    else:\n",
    "        icon_color = 'red'\n",
    "\n",
    "    feature = {\n",
    "        'type': 'Feature',\n",
    "        'geometry': {\n",
    "            'type': 'Point',\n",
    "            'coordinates': [longitude, latitude],\n",
    "        },\n",
    "        'properties': {\n",
    "            'time': date.strftime('%Y-%m-%d'),\n",
    "            'popup': f\"{reservoir_name}<br>Date: {date.strftime('%d-%m-%Y')}<br>Level: {level} m\",\n",
    "            'icon': 'circle',\n",
    "            'iconstyle': {\n",
    "                'color': icon_color,\n",
    "                'fillColor': icon_color,\n",
    "                'fillOpacity': 0.7,\n",
    "                'radius': 5\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "    features.append(feature)\n",
    "\n",
    "\n",
    "# Create a GeoJSON object for the features\n",
    "geojson = {\n",
    "    'type': 'FeatureCollection',\n",
    "    'features': features\n",
    "}\n",
    "\n",
    "# Add the TimestampedGeoJson layer to the map\n",
    "TimestampedGeoJson(\n",
    "    geojson,\n",
    "    period=\"P1D\",\n",
    "    duration=\"P1M\",\n",
    "    add_last_point=True,\n",
    "    auto_play=False,\n",
    "    loop=False,\n",
    "    max_speed=100,\n",
    "    loop_button=True,\n",
    "    date_options=\"YYYY-MM-DD\",\n",
    "    time_slider_drag_update=True\n",
    ").add_to(m)\n",
    "\n",
    "# Save the map\n",
    "m.save(html_output)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "selenium-scrapper",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
